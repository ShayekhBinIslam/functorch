


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch._functorch.make_functional &mdash; functorch nightly documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/togglebutton.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/mystnb.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <!-- Google Analytics -->
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-117752657-2');
    </script>
  
  <!-- End Google Analytics -->
  

  
  <script src="../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torcharrow">
                  <span class="dropdown-title">torcharrow</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorchâ€™s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn about the PyTorch foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href='https://pytorch.org/functorch/versions.html'>nightly (2.0.0a0+gitb2c68c1) &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">functorch: Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../install.html">Install functorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebooks/whirlwind_tour.html">Whirlwind Tour</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ux_limitations.html">UX Limitations</a></li>
</ul>
<p class="caption"><span class="caption-text">functorch API Reference and Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../functorch.html">functorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../experimental.html">functorch.experimental</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../aot_autograd.html">functorch.compile (experimental)</a></li>
</ul>
<p class="caption"><span class="caption-text">functorch Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../notebooks/jacobians_hessians.html">Jacobians, Hessians, hvp, vhp, and more: composing functorch transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebooks/ensembling.html">Model ensembling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebooks/per_sample_grads.html">Per-sample-gradients</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebooks/neural_tangent_kernels.html">Neural Tangent Kernels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebooks/aot_autograd_optimizations.html">AOT Autograd - How to use and optimize?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notebooks/minifier.html">Using the Minifier</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../index.html">Module code</a> &gt;</li>
        
      <li>torch._functorch.make_functional</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torch._functorch.make_functional</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) Facebook, Inc. and its affiliates.</span>
<span class="c1"># All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># This source code is licensed under the BSD-style license found in the</span>
<span class="c1"># LICENSE file in the root directory of this source tree.</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span>
<span class="kn">from</span> <span class="nn">.named_members_polyfill</span> <span class="kn">import</span> <span class="n">_named_parameters</span><span class="p">,</span> <span class="n">_named_buffers</span>
<span class="kn">import</span> <span class="nn">copy</span>

<span class="c1"># Utilities to make nn.Module &quot;functional&quot;</span>
<span class="c1"># In particular the goal is to be able to provide a function that takes as input</span>
<span class="c1"># the parameters and evaluate the nn.Module using fixed inputs.</span>


<span class="k">def</span> <span class="nf">_del_nested_attr</span><span class="p">(</span><span class="n">obj</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">names</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Deletes the attribute specified by the given list of names.</span>
<span class="sd">    For example, to delete the attribute obj.conv.weight,</span>
<span class="sd">    use _del_nested_attr(obj, [&#39;conv&#39;, &#39;weight&#39;])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">names</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="nb">delattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">names</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">_del_nested_attr</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">names</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">names</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>


<span class="k">def</span> <span class="nf">_set_nested_attr</span><span class="p">(</span><span class="n">obj</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">names</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">value</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Set the attribute specified by the given list of names to value.</span>
<span class="sd">    For example, to set the attribute obj.conv.weight,</span>
<span class="sd">    use _del_nested_attr(obj, [&#39;conv&#39;, &#39;weight&#39;], value)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">names</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">names</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">value</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">_set_nested_attr</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">names</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">names</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">value</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_get_nested_attr</span><span class="p">(</span><span class="n">obj</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">names</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">names</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">names</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_get_nested_attr</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">names</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">names</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>


<span class="k">def</span> <span class="nf">raise_parameter_tying_error</span><span class="p">():</span>
    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
        <span class="s2">&quot;make_functional(module): we don&#39;t yet support models that &quot;</span>
        <span class="s2">&quot;do parameter tying (also sometimes known as weight sharing). &quot;</span>
        <span class="s2">&quot;Please try to rewrite your model by replacing all instances of the &quot;</span>
        <span class="s2">&quot;tied parameter with another and/or comment your support in &quot;</span>
        <span class="s2">&quot;https://github.com/pytorch/functorch/issues/446&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">create_names_map</span><span class="p">(</span><span class="n">named_params</span><span class="p">,</span> <span class="n">tied_named_params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    named_params is a dictionary of tensors: {&#39;A&#39;: A, &#39;B&#39;: B}</span>
<span class="sd">    tied_named_params is another dictionary of tensors {&#39;A&#39;: A, &#39;B&#39;: B, &#39;B_tied&#39;: B}</span>
<span class="sd">    with potentially tied (or &#39;duplicated&#39;) tensors</span>

<span class="sd">    This function creates a mapping from the names in named_params to the</span>
<span class="sd">    names in tied_named_params: {&#39;A&#39;: [&#39;A&#39;], &#39;B&#39;: [&#39;B&#39;, &#39;B_tied&#39;]}.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">named_params</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">named_params</span><span class="p">}</span>
    <span class="n">tied_named_params</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">tied_named_params</span><span class="p">}</span>

    <span class="n">tensors_dict_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">named_params</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="n">tied_tensors_dict_keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">tied_named_params</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="k">assert</span> <span class="n">tensors_dict_keys</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="n">tied_tensors_dict_keys</span><span class="p">)</span>

    <span class="n">tensor_to_mapping</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">named_params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">tensor_to_mapping</span><span class="p">[</span><span class="n">tensor</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="p">[])</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">tied_named_params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">assert</span> <span class="n">tensor</span> <span class="ow">in</span> <span class="n">tensor_to_mapping</span>
        <span class="n">tensor_to_mapping</span><span class="p">[</span><span class="n">tensor</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">key</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">))</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">value</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">tensor_to_mapping</span><span class="o">.</span><span class="n">values</span><span class="p">()}</span>
    <span class="k">return</span> <span class="n">result</span>


<span class="k">def</span> <span class="nf">_extract_members</span><span class="p">(</span><span class="n">mod</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">_named_members</span><span class="p">,</span> <span class="n">named_members</span><span class="p">,</span> <span class="n">subclass</span><span class="p">):</span>
    <span class="n">all_named_members</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">_named_members</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">remove_duplicate</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
    <span class="n">named_members</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">named_members</span><span class="p">())</span>
    <span class="n">names_map</span> <span class="o">=</span> <span class="n">create_names_map</span><span class="p">(</span><span class="n">named_members</span><span class="p">,</span> <span class="n">all_named_members</span><span class="p">)</span>

    <span class="c1"># Remove all the members in the model</span>
    <span class="n">memo</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">all_named_members</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">p</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">memo</span><span class="p">:</span>
            <span class="n">memo</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">=</span> <span class="n">subclass</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;meta&#39;</span><span class="p">))</span>
        <span class="n">replacement</span> <span class="o">=</span> <span class="n">memo</span><span class="p">[</span><span class="n">p</span><span class="p">]</span>
        <span class="n">_set_nested_attr</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">),</span> <span class="n">replacement</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">named_members</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">names</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <span class="p">(),</span> <span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">names</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">named_members</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">params</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">names_map</span>


<span class="k">def</span> <span class="nf">extract_weights</span><span class="p">(</span><span class="n">mod</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function removes all the Parameters from the model and</span>
<span class="sd">    return them as a tuple as well as their original attribute names.</span>
<span class="sd">    The weights must be re-loaded with `load_weights` before the model</span>
<span class="sd">    can be used again.</span>
<span class="sd">    Note that this function modifies the model in place and after this</span>
<span class="sd">    call, mod.parameters() will be empty.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_extract_members</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">_named_parameters</span><span class="p">,</span> <span class="n">mod</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">extract_buffers</span><span class="p">(</span><span class="n">mod</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">_extract_members</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">_named_buffers</span><span class="p">,</span> <span class="n">mod</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">load_weights</span><span class="p">(</span><span class="n">mod</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">names</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">params</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">as_params</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Reload a set of weights so that `mod` can be used again to perform a forward pass.</span>
<span class="sd">    Note that the `params` are regular Tensors (that can have history) and so are left</span>
<span class="sd">    as Tensors. This means that mod.parameters() will still be empty after this call.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">names</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">as_params</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
        <span class="n">_del_nested_attr</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">))</span>
        <span class="n">_set_nested_attr</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">),</span> <span class="n">p</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_swap_state</span><span class="p">(</span><span class="n">mod</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">names_map</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">elems</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">attr_names</span><span class="p">),</span> <span class="n">elem</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">names_map</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">elems</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">attr_name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">attr_names</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_get_nested_attr</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">attr_name</span><span class="p">))</span>
            <span class="n">_del_nested_attr</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">attr_name</span><span class="p">)</span>
            <span class="n">_set_nested_attr</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">attr_name</span><span class="p">,</span> <span class="n">elem</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>


<span class="k">def</span> <span class="nf">load_buffers</span><span class="p">(</span><span class="n">mod</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">names</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">buffers</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">as_params</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">names</span><span class="p">,</span> <span class="n">buffers</span><span class="p">):</span>
        <span class="n">_set_nested_attr</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">),</span> <span class="n">p</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">load_state</span><span class="p">(</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">weights</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">weight_names</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">buffers</span><span class="o">=</span><span class="p">(),</span> <span class="n">buffer_names</span><span class="o">=</span><span class="p">()):</span>
    <span class="sd">&quot;&quot;&quot;load_state(model, weights, weight_names, buffers=(), buffer_names=()) -&gt; model</span>

<span class="sd">    load_state takes `weights` and `buffers` and assigns them to the model.</span>
<span class="sd">    This is the inverse operation of `make_functional_deprecated_v1`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">weight_names</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
    <span class="n">load_weights</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">weight_names</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">buffers</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">buffer_names</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">buffers</span><span class="p">)</span>
        <span class="n">load_buffers</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">buffer_names</span><span class="p">,</span> <span class="n">buffers</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>


<span class="k">def</span> <span class="nf">make_functional_deprecated_v1</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;make_functional_deprecated_v1(model) -&gt; weights, func, weight_names</span>

<span class="sd">    Given an nn.Module, make_functional_deprecated_v1 extracts the state (weights)</span>
<span class="sd">    and returns a functional version of the model, `func`. This makes</span>
<span class="sd">    it so that it is possible use transforms over the parameters of</span>
<span class="sd">    `model`.</span>

<span class="sd">    `func` can be invoked as follows:</span>
<span class="sd">    ```</span>
<span class="sd">    x = torch.randn(4, 3)</span>
<span class="sd">    model = nn.Linear(3, 3)</span>
<span class="sd">    weights, func, _ = make_functional_deprecated_v1(model)</span>
<span class="sd">    func(weights, (x,))</span>
<span class="sd">    ```</span>

<span class="sd">    And here is an example of applying the grad transform:</span>
<span class="sd">    ```</span>
<span class="sd">    x = torch.randn(4, 3)</span>
<span class="sd">    model = nn.Linear(3, 3)</span>
<span class="sd">    weights, _, func = make_functional_deprecated_v1(model)</span>
<span class="sd">    grad_weights = grad(func)(weights, (x,))</span>
<span class="sd">    ```</span>

<span class="sd">    To put the state back into a model, use `load_state`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">buffers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">buffers</span><span class="p">())</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">buffers</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;make_functional_deprecated_v1(model): `model` has buffers. Please use &#39;</span>
                           <span class="s1">&#39;make_functional_with_buffers_deprecated_v1(model) instead.&#39;</span><span class="p">)</span>
    <span class="n">weights</span><span class="p">,</span> <span class="n">descriptors</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">extract_weights</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">fun</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">mutable_model</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="n">load_weights</span><span class="p">(</span><span class="n">mutable_model</span><span class="p">,</span> <span class="n">descriptors</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mutable_model</span><span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">weights</span><span class="p">,</span> <span class="n">fun</span><span class="p">,</span> <span class="n">descriptors</span>


<span class="k">def</span> <span class="nf">make_functional_with_buffers_deprecated_v1</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;make_functional_with_buffers_deprecated_v1(model) -&gt; weights, buffers, func, weight_names, buffer_names</span>

<span class="sd">    Given an nn.Module, make_functional_with_buffers_deprecated_v1 extracts the state (weights and buffers)</span>
<span class="sd">    and returns a functional version of the model, `func`.</span>

<span class="sd">    `func` can be invoked as follows:</span>
<span class="sd">    ```</span>
<span class="sd">    x = torch.randn(4, 3)</span>
<span class="sd">    model = nn.Linear(3, 3)</span>
<span class="sd">    weights, buffers, func, _, _ = make_functional_with_buffers_deprecated_v1(model)</span>
<span class="sd">    func(weights, buffers, (x,))</span>
<span class="sd">    ```</span>

<span class="sd">    And here is an example of applying the grad transform:</span>
<span class="sd">    ```</span>
<span class="sd">    x = torch.randn(4, 3)</span>
<span class="sd">    model = nn.Linear(3, 3)</span>
<span class="sd">    weights, buffers, func, _, _ = make_functional_with_buffers_deprecated_v1(model)</span>
<span class="sd">    func(weights, buffers, (x,))</span>
<span class="sd">    grad_weights = grad(func)(weights, buffers, (x,))</span>
<span class="sd">    ```</span>

<span class="sd">    To put the state back into a model, use `load_state`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">weights</span><span class="p">,</span> <span class="n">weight_descriptors</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">extract_weights</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">buffers</span><span class="p">,</span> <span class="n">buf_descriptors</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">extract_buffers</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">fun</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">buffers</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="n">mutable_model</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="n">load_weights</span><span class="p">(</span><span class="n">mutable_model</span><span class="p">,</span> <span class="n">weight_descriptors</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
        <span class="n">load_buffers</span><span class="p">(</span><span class="n">mutable_model</span><span class="p">,</span> <span class="n">buf_descriptors</span><span class="p">,</span> <span class="n">buffers</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mutable_model</span><span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">weights</span><span class="p">,</span> <span class="n">buffers</span><span class="p">,</span> <span class="n">fun</span><span class="p">,</span> <span class="n">weight_descriptors</span><span class="p">,</span> <span class="n">buf_descriptors</span>


<span class="k">class</span> <span class="nc">FunctionalModuleWithBuffers</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This is the callable object returned by :func:`make_functional_with_buffers`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stateless_model</span><span class="p">,</span> <span class="n">param_names</span><span class="p">,</span> <span class="n">buffer_names</span><span class="p">,</span>
                 <span class="n">param_names_map</span><span class="p">,</span> <span class="n">buffer_names_map</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FunctionalModuleWithBuffers</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stateless_model</span> <span class="o">=</span> <span class="n">stateless_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param_names</span> <span class="o">=</span> <span class="n">param_names</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">buffer_names</span> <span class="o">=</span> <span class="n">buffer_names</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">all_names_map</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">param_names_map</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_names_map</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">buffer_names_map</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_create_from</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">disable_autograd_tracking</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="c1"># TODO: We don&#39;t need to copy the model to create a stateless copy</span>
        <span class="n">model_copy</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="n">params</span><span class="p">,</span> <span class="n">param_names</span><span class="p">,</span> <span class="n">param_names_map</span> <span class="o">=</span> <span class="n">extract_weights</span><span class="p">(</span><span class="n">model_copy</span><span class="p">)</span>
        <span class="n">buffers</span><span class="p">,</span> <span class="n">buffer_names</span><span class="p">,</span> <span class="n">buffer_names_map</span> <span class="o">=</span> <span class="n">extract_buffers</span><span class="p">(</span><span class="n">model_copy</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">disable_autograd_tracking</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
                <span class="n">param</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">FunctionalModuleWithBuffers</span><span class="p">(</span><span class="n">model_copy</span><span class="p">,</span> <span class="n">param_names</span><span class="p">,</span> <span class="n">buffer_names</span><span class="p">,</span>
                                        <span class="n">param_names_map</span><span class="p">,</span> <span class="n">buffer_names_map</span><span class="p">),</span>
            <span class="n">params</span><span class="p">,</span>
            <span class="n">buffers</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">buffers</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="c1"># Temporarily load the state back onto self.stateless_model</span>
        <span class="n">old_state</span> <span class="o">=</span> <span class="n">_swap_state</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">stateless_model</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">all_names_map</span><span class="p">,</span>
            <span class="nb">list</span><span class="p">(</span><span class="n">params</span><span class="p">)</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">buffers</span><span class="p">))</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">stateless_model</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="c1"># Remove the loaded state on self.stateless_model</span>
            <span class="n">_swap_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stateless_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_names_map</span><span class="p">,</span> <span class="n">old_state</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">FunctionalModule</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This is the callable object returned by :func:`make_functional`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stateless_model</span><span class="p">,</span> <span class="n">param_names</span><span class="p">,</span> <span class="n">names_map</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FunctionalModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stateless_model</span> <span class="o">=</span> <span class="n">stateless_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param_names</span> <span class="o">=</span> <span class="n">param_names</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">names_map</span> <span class="o">=</span> <span class="n">names_map</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_create_from</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">disable_autograd_tracking</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="c1"># TODO: We don&#39;t need to copy the model to create a stateless copy</span>
        <span class="n">model_copy</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="n">params</span><span class="p">,</span> <span class="n">param_names</span><span class="p">,</span> <span class="n">names_map</span> <span class="o">=</span> <span class="n">extract_weights</span><span class="p">(</span><span class="n">model_copy</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">disable_autograd_tracking</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
                <span class="n">param</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">FunctionalModule</span><span class="p">(</span><span class="n">model_copy</span><span class="p">,</span> <span class="n">param_names</span><span class="p">,</span> <span class="n">names_map</span><span class="p">),</span> <span class="n">params</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="c1"># Temporarily load the state back onto self.stateless_model</span>
        <span class="n">old_state</span> <span class="o">=</span> <span class="n">_swap_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stateless_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">names_map</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">stateless_model</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="c1"># Remove the loaded state on self.stateless_model</span>
            <span class="n">_swap_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stateless_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">names_map</span><span class="p">,</span> <span class="n">old_state</span><span class="p">)</span>


<div class="viewcode-block" id="make_functional"><a class="viewcode-back" href="../../../generated/functorch.make_functional.html#functorch.make_functional">[docs]</a><span class="k">def</span> <span class="nf">make_functional</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">disable_autograd_tracking</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;make_functional(model, disable_autograd_tracking=False) -&gt; func, params</span>

<span class="sd">    Given a ``torch.nn.Module``, :func:`make_functional` extracts the state</span>
<span class="sd">    (params) and returns a functional version of the model, ``func``. This</span>
<span class="sd">    makes it so that it is possible use transforms over the parameters of</span>
<span class="sd">    ``model``.</span>

<span class="sd">    ``func`` can be invoked as follows:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import torch</span>
<span class="sd">        import torch.nn as nn</span>
<span class="sd">        from functorch import make_functional</span>

<span class="sd">        x = torch.randn(4, 3)</span>
<span class="sd">        model = nn.Linear(3, 3)</span>
<span class="sd">        func, params = make_functional(model)</span>
<span class="sd">        func(params, x)</span>

<span class="sd">    And here is an example of applying the grad transform over the parameters</span>
<span class="sd">    of a model.</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import torch</span>
<span class="sd">        import torch.nn as nn</span>
<span class="sd">        from functorch import make_functional, grad</span>

<span class="sd">        x = torch.randn(4, 3)</span>
<span class="sd">        t = torch.randn(4, 3)</span>
<span class="sd">        model = nn.Linear(3, 3)</span>
<span class="sd">        func, params = make_functional(model)</span>

<span class="sd">        def compute_loss(params, x, t):</span>
<span class="sd">            y = func(params, x)</span>
<span class="sd">            return nn.functional.mse_loss(y, t)</span>

<span class="sd">        grad_weights = grad(compute_loss)(params, x, t)</span>

<span class="sd">    If the model has any buffers, please use :func:`make_functional_with_buffers` instead.</span>

<span class="sd">    Args:</span>
<span class="sd">        model (torch.nn.Module): Input model.</span>
<span class="sd">        disable_autograd_tracking (bool): Flag to disable gradients tracking for output parameters.</span>
<span class="sd">            The returned params are unrelated to the set of params from the original model. If False (default),</span>
<span class="sd">            the params will have ``requires_grad=True`` on them (aka they will be trackable with regular</span>
<span class="sd">            PyTorch autograd), matching the requires_grad-ness of the params from the original model.</span>
<span class="sd">            Otherwise, the returned params will have ``requires_grad=False``. Default, False.</span>
<span class="sd">            If you plan on using regular PyTorch autograd (e.g., if you want to call ``.backward()`` or</span>
<span class="sd">            ``torch.autograd.grad()``, then set ``disable_autograd_tracking=False``.</span>
<span class="sd">            Otherwise, if you&#39;re only planning on using functorch&#39;s gradient transforms,</span>
<span class="sd">            then please set ``disable_autograd_tracking=True`` to avoid unnecessarily tracking</span>
<span class="sd">            history with PyTorch autograd.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">buffers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">buffers</span><span class="p">())</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">buffers</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;make_functional(model): `model` has buffers. Please use &#39;</span>
                           <span class="s1">&#39;make_functional_with_buffers(model) instead.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">FunctionalModule</span><span class="o">.</span><span class="n">_create_from</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">disable_autograd_tracking</span><span class="o">=</span><span class="n">disable_autograd_tracking</span><span class="p">)</span></div>


<div class="viewcode-block" id="make_functional_with_buffers"><a class="viewcode-back" href="../../../generated/functorch.make_functional_with_buffers.html#functorch.make_functional_with_buffers">[docs]</a><span class="k">def</span> <span class="nf">make_functional_with_buffers</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">disable_autograd_tracking</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;make_functional_with_buffers(model, disable_autograd_tracking=False) -&gt; func, params, buffers</span>

<span class="sd">    Given a ``torch.nn.Module``, make_functional_with_buffers extracts the</span>
<span class="sd">    state (params and buffers) and returns a functional version of the model</span>
<span class="sd">    ``func`` that can be invoked like a function.</span>

<span class="sd">    ``func`` can be invoked as follows:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import torch</span>
<span class="sd">        import torch.nn as nn</span>
<span class="sd">        from functorch import make_functional_with_buffers</span>

<span class="sd">        x = torch.randn(4, 3)</span>
<span class="sd">        model = nn.Linear(3, 3)</span>
<span class="sd">        func, params, buffers = make_functional_with_buffers(model)</span>
<span class="sd">        func(params, buffers, x)</span>

<span class="sd">    And here is an example of applying the grad transform over the parameters</span>
<span class="sd">    of a model:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import torch</span>
<span class="sd">        import torch.nn as nn</span>
<span class="sd">        from functorch import make_functional_with_buffers, grad</span>

<span class="sd">        x = torch.randn(4, 3)</span>
<span class="sd">        t = torch.randn(4, 3)</span>
<span class="sd">        model = nn.Linear(3, 3)</span>
<span class="sd">        func, params, buffers = make_functional_with_buffers(model)</span>

<span class="sd">        def compute_loss(params, buffers, x, t):</span>
<span class="sd">            y = func(params, buffers, x)</span>
<span class="sd">            return nn.functional.mse_loss(y, t)</span>

<span class="sd">        grad_weights = grad(compute_loss)(params, buffers, x, t)</span>

<span class="sd">    Args:</span>
<span class="sd">        model (torch.nn.Module): Input model.</span>
<span class="sd">        disable_autograd_tracking (bool): Flag to disable gradients tracking for output parameters.</span>
<span class="sd">            The returned params are unrelated to the set of params from the original model. If False (default),</span>
<span class="sd">            the params will have ``requires_grad=True`` on them (aka they will be trackable with regular</span>
<span class="sd">            PyTorch autograd), matching the requires_grad-ness of the params from the original model.</span>
<span class="sd">            Otherwise, the returned params will have ``requires_grad=False``. Default, False.</span>
<span class="sd">            If you plan on using regular PyTorch autograd (e.g., if you want to call ``.backward()`` or</span>
<span class="sd">            ``torch.autograd.grad()``, then set ``disable_autograd_tracking=False``.</span>
<span class="sd">            Otherwise, if you&#39;re only planning on using functorch&#39;s gradient transforms,</span>
<span class="sd">            then please set ``disable_autograd_tracking=True`` to avoid unnecessarily tracking</span>
<span class="sd">            history with PyTorch autograd.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">FunctionalModuleWithBuffers</span><span class="o">.</span><span class="n">_create_from</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">disable_autograd_tracking</span><span class="o">=</span><span class="n">disable_autograd_tracking</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">transpose_stack</span><span class="p">(</span><span class="n">tuple_of_tuple_of_tensors</span><span class="p">):</span>
    <span class="n">tuple_of_tuple_of_tensors</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">tuple_of_tuple_of_tensors</span><span class="p">))</span>
    <span class="n">results</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">shards</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span> <span class="k">for</span> <span class="n">shards</span> <span class="ow">in</span> <span class="n">tuple_of_tuple_of_tensors</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">results</span>


<div class="viewcode-block" id="combine_state_for_ensemble"><a class="viewcode-back" href="../../../generated/functorch.combine_state_for_ensemble.html#functorch.combine_state_for_ensemble">[docs]</a><span class="k">def</span> <span class="nf">combine_state_for_ensemble</span><span class="p">(</span><span class="n">models</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;combine_state_for_ensemble(models) -&gt; func, params, buffers</span>

<span class="sd">    Prepares a list of torch.nn.Modules for ensembling with :func:`vmap`.</span>

<span class="sd">    Given a list of ``M`` ``nn.Modules`` of the same class, stacks all of their</span>
<span class="sd">    parameters and buffers together to make ``params`` and ``buffers``.</span>
<span class="sd">    Each parameter and buffer in the result will have an additional dimension</span>
<span class="sd">    of size ``M``.</span>

<span class="sd">    :func:`combine_state_for_ensemble` also returns ``func``, a functional</span>
<span class="sd">    version of one of the models in :attr:`models`. One cannot directly run</span>
<span class="sd">    ``func(params, buffers, *args, **kwargs)`` directly, you probably want to</span>
<span class="sd">    use ``vmap(func, ...)(params, buffers, *args, **kwargs)``</span>

<span class="sd">    Here&#39;s an example of how to ensemble over a very simple model:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        num_models = 5</span>
<span class="sd">        batch_size = 64</span>
<span class="sd">        in_features, out_features = 3, 3</span>
<span class="sd">        models = [torch.nn.Linear(in_features, out_features) for i in range(num_models)]</span>
<span class="sd">        data = torch.randn(batch_size, 3)</span>

<span class="sd">        fmodel, params, buffers = combine_state_for_ensemble(models)</span>
<span class="sd">        output = vmap(fmodel, (0, 0, None))(params, buffers, data)</span>

<span class="sd">        assert output.shape == (num_models, batch_size, out_features)</span>

<span class="sd">    .. warning::</span>
<span class="sd">        All of the modules being stacked together must be the same (except for</span>
<span class="sd">        the values of their parameters/buffers). For example, they should be in the</span>
<span class="sd">        same mode (training vs eval).</span>

<span class="sd">        This API is subject to change -- we&#39;re investigating better ways to</span>
<span class="sd">        create ensembles and would love your feedback how to improve this.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">models</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;combine_state_for_ensemble: Expected at least one model, got 0.&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="nb">all</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">training</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">models</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">all</span><span class="p">(</span><span class="ow">not</span> <span class="n">m</span><span class="o">.</span><span class="n">training</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">models</span><span class="p">)):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;combine_state_for_ensemble: Expected all models to &#39;</span>
                           <span class="s1">&#39;have the same training/eval mode.&#39;</span><span class="p">)</span>
    <span class="n">model0_typ</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">model0_typ</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">models</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;combine_state_for_ensemble: Expected all models to &#39;</span>
                           <span class="s1">&#39;be of the same class.&#39;</span><span class="p">)</span>
    <span class="n">funcs</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">buffers</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">make_functional_with_buffers</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
                                   <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">])</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">transpose_stack</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">buffers</span> <span class="o">=</span> <span class="n">transpose_stack</span><span class="p">(</span><span class="n">buffers</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">funcs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">params</span><span class="p">,</span> <span class="n">buffers</span></div>


<span class="k">def</span> <span class="nf">functional_init</span><span class="p">(</span><span class="n">model_class</span><span class="p">,</span> <span class="n">ensemble_shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">wrapped</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ensemble_shape</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;NYI: ensemble_shape with more than 1 element&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ensemble_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">model_class</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">make_functional_deprecated_v1</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="n">num_models</span> <span class="o">=</span> <span class="n">ensemble_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">num_models</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;num_models </span><span class="si">{</span><span class="n">num_models</span><span class="si">}</span><span class="s2"> should be &gt; 0&quot;</span><span class="p">)</span>
        <span class="c1"># NB: Not very efficient, more of a POC</span>
        <span class="n">models</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">model_class</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                       <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_models</span><span class="p">))</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">names</span> <span class="o">=</span> <span class="n">make_functional_deprecated_v1</span><span class="p">(</span><span class="n">model_class</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">make_functional_deprecated_v1</span><span class="p">(</span><span class="n">model</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">)</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">weights</span><span class="p">))</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">shards</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span> <span class="k">for</span> <span class="n">shards</span> <span class="ow">in</span> <span class="n">weights</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">weights</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">names</span>
    <span class="k">return</span> <span class="n">wrapped</span>


<span class="k">def</span> <span class="nf">functional_init_with_buffers</span><span class="p">(</span><span class="n">model_class</span><span class="p">,</span> <span class="n">ensemble_shape</span><span class="o">=</span><span class="p">(),</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">wrapped</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ensemble_shape</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;NYI: ensemble_shape with more than 1 element&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ensemble_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">model_class</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">make_functional_deprecated_v1</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="n">num_models</span> <span class="o">=</span> <span class="n">ensemble_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">num_models</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;num_models </span><span class="si">{</span><span class="n">num_models</span><span class="si">}</span><span class="s2"> should be &gt; 0&quot;</span><span class="p">)</span>
        <span class="c1"># NB: Not very efficient, more of a POC</span>
        <span class="n">models</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">model_class</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                       <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_models</span><span class="p">))</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">weight_names</span><span class="p">,</span> <span class="n">buffer_names</span> <span class="o">=</span> \
            <span class="n">make_functional_with_buffers_deprecated_v1</span><span class="p">(</span><span class="n">model_class</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span>
        <span class="n">weights</span><span class="p">,</span> <span class="n">buffers</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="nb">tuple</span><span class="p">(</span><span class="n">make_functional_with_buffers_deprecated_v1</span><span class="p">(</span><span class="n">model</span><span class="p">)[:</span><span class="mi">2</span><span class="p">]</span>
                                      <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">))</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">weights</span><span class="p">))</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">shards</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span> <span class="k">for</span> <span class="n">shards</span> <span class="ow">in</span> <span class="n">weights</span><span class="p">)</span>
        <span class="n">buffers</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">buffers</span><span class="p">))</span>
        <span class="n">buffers</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">shards</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span> <span class="k">for</span> <span class="n">shards</span> <span class="ow">in</span> <span class="n">buffers</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">weights</span><span class="p">,</span> <span class="n">buffers</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">weight_names</span><span class="p">,</span> <span class="n">buffer_names</span>
    <span class="k">return</span> <span class="n">wrapped</span>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright PyTorch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
         <script src="../../../_static/jquery.js"></script>
         <script src="../../../_static/underscore.js"></script>
         <script src="../../../_static/doctools.js"></script>
         <script src="../../../_static/clipboard.min.js"></script>
         <script src="../../../_static/copybutton.js"></script>
         <script >let toggleHintShow = 'Click to show';</script>
         <script >let toggleHintHide = 'Click to hide';</script>
         <script >let toggleOpenOnPrint = 'true';</script>
         <script src="../../../_static/togglebutton.js"></script>
         <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
     

  

  <script type="text/javascript" src="../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>Â© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>
            
          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/torcharrow">torcharrow</a>
            </li>

            <li>
              <a href="https://pytorch.org/data">TorchData</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchrec">TorchRec</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>
            
           <ul class="resources-mobile-menu-items">

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>

            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>